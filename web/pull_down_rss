#! /usr/bin/env nix-shell
#! nix-shell -p libxslt xmlstarlet -i bash

# Grabs RSS feeds and dumps them in ~/.cache
# Used to work around things imm doesn't support (e.g. HTTPS)

function stripNonAscii {
    tr -cd '[:print:]\n'
}

function fixRss {
    # Set the author to $1, to avoid newlines
    xmlstarlet ed -u "//author" -v "$1" |

    # Append today as the pubDate, then remove all but the first pubDate (i.e.
    # append today as the pubDate, if none is given)
    xmlstarlet ed -s //item -t elem -n pubDate             \
                  -v "$(date -d "today 00:00" --rfc-2822)" \
                  -d '//item/author[position() != 1]'
}

function atomToRss {
    xsltproc ~/System/Programs/atom2rss-exslt.xsl "$1.atom" |
        fixRss "$1" > "$1.rss"
}

function get {
    timeout 20 wget --no-check-certificate "$@"
}

function getAtom {
    get -O - "$2" | stripNonAscii > "$1.atom"
    atomToRss "$1"
}

function getYouTube {
    get -O - "http://www.youtube.com/feeds/videos.xml?channel_id=$2" |
        stripNonAscii > "$1.atom"
    atomToRss "$1"
}

function getRss {
    get -O - "$2" | stripNonAscii | fixRss "$1" > "$1.rss"
}

function getCourier {
    # Edit URL http://feed43.com/feed.html?name=dundee_courier
    COURIER="$HOME/.cache/rss/DundeeCourier.rss"
    if [[ -e "$COURIER" ]]
    then
        # Feed43 don't like polling more than every 6 hours
        if test "$(find "$COURIER" -mmin +360)"
        then
            getRss "DundeeCourier" "http://feed43.com/dundee_courier.xml"
        fi
    else
        getRss "DundeeCourier" "http://feed43.com/dundee_courier.xml"
    fi
}

mkdir -p ~/.cache/rss
cd ~/.cache/rss || {
    echo "Couldn't cd to ~/.cache/rss" 1>&2
    exit 1
}

# Configurable feeds
while read -r FEED
do
    TYPE=$(echo "$FEED" | cut -f1)
    NAME=$(echo "$FEED" | cut -f2)
     URL=$(echo "$FEED" | cut -f3)

    case "$TYPE" in
        rss)
            getRss "$NAME" "$URL"
            ;;
        atom)
            getAtom "$NAME" "$URL"
            ;;
        youtube)
            getYouTube "$NAME" "$URL"
            ;;
        *)
            echo "Can't handle '$FEED'" 1>&2
            ;;
    esac
done < ~/.feeds

# Scrape BBC iPlayer

iplayer_to_rss

# Scrape the Dundee Courier

getCourier
